{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TigerGraph Graph-RAG for Document Question Answering\n",
    "\n",
    "This notebook demostrates how to use TigerGraph Graph-RAG (currently in Beta), an AI assistant for your TigerGraph databases. TigerGraph Graph-RAG enables you to ask questions in natural language about your document data stored in TigerGraph and get answers in a human-readable format. GraphRAG is a graph-based retrieval-augmented generation approach that is used to answer questions about the document data stored in TigerGraph. TigerGraph Graph-RAG is built to help users get started with GraphRAG and to provide a seamless experience for users to interact with their document data within TigerGraph.\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "\n",
    "* Follow [Docker setup ](https://github.com/tigergraph/ecosys/blob/master/demos/guru_scripts/docker/README.md) to set up your docker Environment.\n",
    "* Please follow (Overview of installing Docker Compose)[https://docs.docker.com/compose/install/] to install Docker Compose for your platform accordingly.\n",
    "\n",
    "\n",
    "#### TigerGraph Docker Image\n",
    "\n",
    "To use TigerGraph Community Edition without a license key, download the corresponding docker image from https://dl.tigergraph.com/ and load to Docker:\n",
    "```\n",
    "docker load -i ./tigergraph-4.2.0-community-docker-image.tar.gz\n",
    "docker images\n",
    "```\n",
    "\n",
    "You should be able to find `tigergraph/community:4.2.0` in the image list.\n",
    "\n",
    "#### Graph-RAG Docker Images\n",
    "\n",
    "The following images are also needed for TigerGraph Graph-RAG. Docker Compose will automatically download them, but you can download them manually if preferred:\n",
    "\n",
    "```\n",
    "docker pull <image_name>\n",
    "\n",
    "tigergraphml/copilot:latest\n",
    "tigergraphml/ecc:latest\n",
    "tigergraphml/chat-history:latest\n",
    "tigergraphml/copilot-ui:latest\n",
    "nginx:latest\n",
    "```\n",
    "### Deploy Graph-RAG with Docker Compose\n",
    "#### Get docker-compose file\n",
    "Download the [docker-compose.yml](https://raw.githubusercontent.com/tigergraph/ecosys/refs/heads/master/tutorials/copilot/docker-compose.yml) file directly\n",
    "\n",
    "The Docker Compose file contains all dependencies for Graph-RAG including a TigerGraph database. If you want to use a separate TigerGraph instance, you can comment out the `tigergraph` section from the docker compose file and restart all services. However, please follow the instructions below to make sure your standalone TigerGraph server is accessible from other Graph-RAG containers.\n",
    "\n",
    "#### Set up configurations\n",
    "\n",
    "Next, download the following configuration files and put them in a `configs` subdirectory of the directory contains the Docker Compose file:\n",
    "* [configs/db_config.json](https://raw.githubusercontent.com/tigergraph/ecosys/refs/heads/master/tutorials/copilot/configs/db_config.json)\n",
    "* [configs/llm_config.json](https://raw.githubusercontent.com/tigergraph/ecosys/refs/heads/master/tutorials/copilot/configs/llm_config.json)\n",
    "* [configs/chat_config.json](https://raw.githubusercontent.com/tigergraph/ecosys/refs/heads/master/tutorials/copilot/configs/chat_config.json)\n",
    "* [configs/nginx.conf](https://raw.githubusercontent.com/tigergraph/ecosys/refs/heads/master/tutorials/copilot/configs/nginx.conf)\n",
    "\n",
    "#### Adjust configurations\n",
    "\n",
    "Edit `configs/llm_config.json` and replace `<YOUR_OPENAI_API_KEY>` to your own OPENAI_API_KEY. \n",
    " \n",
    "> If desired, you can also change the model to be used for the embedding service and completion service to your preferred models to adjust the output from the LLM service.\n",
    "\n",
    "#### Start all services\n",
    "\n",
    "Now, simply run `docker compose up -d` and wait for all the services to start.\n",
    "\n",
    "## Build GraphRAG From Scratch\n",
    "\n",
    "If you want to experience the whole process of Copilot, you can build the GraphRAG from scratch. However, please review the LLM model and service setting carefully because it will cost some money to re-generate embedding and data structure for the raw data.\n",
    "\n",
    "#### Step 1: Database Connection Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"./configs/db_config.json\") as cfg:\n",
    "        config = json.load(cfg)\n",
    "\n",
    "    config[\"hostname\"] = \"http://192.168.11.11\"\n",
    "    config[\"username\"] = \"tigergraph\"\n",
    "    config[\"password\"] = \"tigergraph\"\n",
    "    \n",
    "    # We first create a connection to the database\n",
    "    conn = TigerGraphConnection(\n",
    "        host=config[\"hostname\"],\n",
    "        username=config[\"username\"],\n",
    "        password=config[\"password\"],\n",
    "        restppPort=config[\"restppPort\"],\n",
    "    )\n",
    "    conn.graphname = \"TigerGraphRAG_demo\"\n",
    "\n",
    "conn.gsql(f\"\"\"CREATE GRAPH {conn.graphname}()\"\"\")\n",
    "# And then add Graph-RAG's address to the connection. This address\n",
    "# is the host's address where the Graph-RAG container is running.\n",
    "\n",
    "\n",
    "conn.getToken()\n",
    "\n",
    "# And then add Graph-RAG's address to the connection. This address\n",
    "# is the host's address where the Graph-RAG container is running.\n",
    "conn.ai.configureCoPilotHost(\"http://192.168.11.11:8000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Initialize Graph and Ingest Data\n",
    "\n",
    "We provide utilities to setup your TigerGraph database with a schema and load your desired documents. In this example, we are utilizing the TigerGraph documentation as our dataset. The documents are processed into a JSONL file of the following format:\n",
    "\n",
    "```json\n",
    "{\"url\": \"some_url_here\", \"content\": \"Text of the document\"}\n",
    "```\n",
    "\n",
    "The following code cell will run schema change jobs for `TigerGraphRAG_demo`, including basic schema, vector embeddings, indexing and install retriever and related queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_name': 'http://tigergraph',\n",
       " 'schema_creation_status': '\"Using graph \\'TigerGraphRAG_demo\\'\\\\nSuccessfully created schema change jobs: [add_supportai_schema].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_schema\\\\nDoing schema change on graph \\'TigerGraphRAG_demo\\' (current version: 0)\\\\nTrying to add local vertex \\'DocumentChunk\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'Document\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'Concept\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'Entity\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'Relationship\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'DocumentCollection\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'Content\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'EntityType\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'Community\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local vertex \\'ResolvedEntity\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'HAS_CONTENT\\' and its reverse edge \\'reverse_HAS_CONTENT\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'IS_CHILD_OF\\' and its reverse edge \\'reverse_IS_CHILD_OF\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'IS_HEAD_OF\\' and its reverse edge \\'reverse_IS_HEAD_OF\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'HAS_TAIL\\' and its reverse edge \\'reverse_HAS_TAIL\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'DESCRIBES_RELATIONSHIP\\' and its reverse edge \\'reverse_DESCRIBES_RELATIONSHIP\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'DESCRIBES_ENTITY\\' and its reverse edge \\'reverse_DESCRIBES_ENTITY\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'CONTAINS_ENTITY\\' and its reverse edge \\'reverse_CONTAINS_ENTITY\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'MENTIONS_RELATIONSHIP\\' and its reverse edge \\'reverse_MENTIONS_RELATIONSHIP\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'IS_AFTER\\' and its reverse edge \\'reverse_IS_AFTER\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'HAS_CHILD\\' and its reverse edge \\'reverse_HAS_CHILD\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'HAS_RELATIONSHIP\\' and its reverse edge \\'reverse_HAS_RELATIONSHIP\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'CONTAINS_DOCUMENT\\' and its reverse edge \\'reverse_CONTAINS_DOCUMENT\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'ENTITY_HAS_TYPE\\' and its reverse edge \\'reverse_ENTITY_HAS_TYPE\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'RELATIONSHIP_TYPE\\' and its reverse edge \\'reverse_RELATIONSHIP_TYPE\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'RELATIONSHIP\\' and its reverse edge \\'reverse_RELATIONSHIP\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'RESOLVES_TO\\' and its reverse edge \\'reverse_RESOLVES_TO\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'RESOLVED_RELATIONSHIP\\' and its reverse edge \\'reverse_RESOLVED_RELATIONSHIP\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'IN_COMMUNITY\\' and its reverse edge \\'reverse_IN_COMMUNITY\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'LINKS_TO\\' and its reverse edge \\'reverse_LINKS_TO\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add local edge \\'HAS_PARENT\\' and its reverse edge \\'reverse_HAS_PARENT\\' to the graph \\'TigerGraphRAG_demo\\'.\\\\n\\\\nGraph TigerGraphRAG_demo updated to new version 1\\\\nThe job add_supportai_schema completes in 2.584 seconds!\\\\nLocal schema change succeeded. Using graph \\'TigerGraphRAG_demo\\'\\\\nSuccessfully created schema change jobs: [add_supportai_vector].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_vector\\\\nDoing schema change on graph \\'TigerGraphRAG_demo\\' (current version: 1)\\\\n\\\\nGraph TigerGraphRAG_demo updated to new version 2\\\\nThe job add_supportai_vector completes in 2.288 seconds!\\\\nLocal schema change succeeded.\"',\n",
       " 'index_creation_status': '\"Using graph \\'TigerGraphRAG_demo\\'\\\\nSuccessfully created schema change jobs: [add_supportai_indexes].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_indexes\\\\nDoing schema change on graph \\'TigerGraphRAG_demo\\' (current version: 2)\\\\nTrying to add index \\'doc_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Document\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'doc_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Document\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'doc_epoch_processing_indexepoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Document\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'doc_chunk_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'DocumentChunk\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'DocumentChunk\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'DocumentChunk\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'concept_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Concept\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'concept_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Concept\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\nTrying to add index \\'concept_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Concept\\' on the graph \\'TigerGraphRAG_demo\\'.\\\\n\\\\nGraph TigerGraphRAG_demo updated to new version 3\\\\nThe job add_supportai_indexes completes in 1.972 seconds!\\\\nLocal schema change succeeded.\"',\n",
       " 'query_creation_status': '\"Using graph \\'TigerGraphRAG_demo\\'\\\\nStart installing queries, about 1 minute ...\\\\nUpdate_Vertices_Processing_Status query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/Update_Vertices_Processing_Status?processed_vertices[INDEX]=VALUE&processed_vertices[INDEX].type=VERTEX_TYPE\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nSelected_Set_Display query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/Selected_Set_Display?json_list_vts=VALUE\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nHNSW_Content_Search query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/HNSW_Content_Search?[json_list_vts=VALUE]&[v_type=VALUE]&[verbose=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nScan_For_Updates query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/Scan_For_Updates?[v_type=VALUE]&[expire_window=VALUE]&[num_samples=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nHNSW_Overlap_Display query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/HNSW_Overlap_Display?json_list_vts=VALUE&[num_hops=VALUE]&[num_seen_min=VALUE]&[chunk_only=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nHNSW_Chunk_Sibling_Search query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/HNSW_Chunk_Sibling_Search?[json_list_vts=VALUE]&[v_type=VALUE]&[lookback=VALUE]&[lookahead=VALUE]&[verbose=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nHNSW_Overlap_Search query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/HNSW_Overlap_Search?[json_list_vts=VALUE]&[num_hops=VALUE]&[num_seen_min=VALUE]&[chunk_only=VALUE]&[doc_only=VALUE]&[verbose=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nGraphRAG_Community_Display query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/GraphRAG_Community_Display?json_list_vts=VALUE&[community_level=VALUE]&[with_chunk=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nGraphRAG_Community_Search query: curl -X GET \\'http://127.0.0.1:14240/restpp/query/TigerGraphRAG_demo/GraphRAG_Community_Search?[json_list_vts=VALUE]&[community_level=VALUE]&[with_chunk=VALUE]&[with_doc=VALUE]&[verbose=VALUE]\\'. Add -H \\\\\"Authorization: Bearer TOKEN\\\\\" if authentication is enabled.\\\\nSelect \\'m1\\' as compile server, now connecting ...\\\\nNode \\'m1\\' is prepared as compile server.\\\\n\\\\n[                                                                                     ] 0% (0/9)   \\\\n[                                                                                     ] 0% (0/9)   \\\\n[======                                                                               ] 6% (0/9)   \\\\n[============                                                                         ] 13% (1/9)  \\\\n[=================                                                                    ] 20% (1/9)  \\\\n[=======================                                                              ] 27% (2/9)  \\\\n[=============================                                                        ] 33% (2/9)  \\\\n[==================================                                                   ] 40% (3/9)  \\\\n[========================================                                             ] 47% (4/9)  \\\\n[==============================================                                       ] 54% (4/9)  \\\\n[====================================================                                 ] 61% (5/9)  \\\\n[=========================================================                            ] 67% (6/9)  \\\\n[===============================================================                      ] 74% (6/9)  \\\\n[=====================================================================                ] 81% (7/9)  \\\\n[===========================================================================          ] 88% (7/9)  \\\\n[=================================================================================    ] 95% (8/9)  \\\\n[=====================================================================================] 100% (9/9) \\\\nQuery installation finished.\"'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.initializeSupportAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Ingest Data\n",
    "\n",
    "The following code will ingest data using a local loading job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(conn: TigerGraphConnection):\n",
    "    load_job = \"\"\"CREATE LOADING JOB load_documents_content_as_json {\n",
    "    DEFINE FILENAME DocumentContent;\n",
    "    LOAD DocumentContent TO TEMP_TABLE tc (doc_id, doc_type, content) VALUES (flatten_json_array($0, $\"doc_id\", $\"doc_type\", $\"content\")) USING SEPARATOR=\"|||||||||||\";\n",
    "\n",
    "    LOAD TEMP_TABLE tc TO VERTEX Document VALUES($\"doc_id\", gsql_current_time_epoch(0), _, _);\n",
    "    LOAD TEMP_TABLE tc TO VERTEX Content VALUES($\"doc_id\", $\"doc_type\", $\"content\", gsql_current_time_epoch(0));\n",
    "    LOAD TEMP_TABLE tc TO EDGE HAS_CONTENT VALUES($\"doc_id\" Document, $\"doc_id\" Content);\n",
    "    }\"\"\"\n",
    "    \n",
    "    conn.gsql(f\"USE GRAPH {conn.graphname}\\n{load_job}\")\n",
    "    conn.runLoadingJobWithFile(\"./data/tg_tutorials.jsonl\", \"DocumentContent\", \"load_documents_content_as_json\", sep=\"|||||||||||||\")\n",
    "load_data(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, create and run DocumentIngest for data files on Cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = \"\"\n",
    "sec = \"\"\n",
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"s3\",\n",
    "    data_source_config={\"aws_access_key\": access, \"aws_secret_key\": sec},\n",
    "    loader_config={\"doc_id_field\": \"url\", \"content_field\": \"content\", \"doc_type\": \"\"},\n",
    "    file_format=\"json\",\n",
    ")\n",
    "conn.ai.runDocumentIngest(res[\"load_job_id\"], res[\"data_source_id\"], \"s3://tg-documentation/pytg_current/pytg_current.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Build Knowledge Graph \n",
    "\n",
    "The following code builds the knowledge graph by performing chunking, embedding, upserting, and extraction using an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'submitted'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.forceConsistencyUpdate(method=\"graphrag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Document Search Methods and LLM Generated Responses\n",
    "\n",
    "\n",
    "TigerGraph CoPilot provides multiple methods to search documents in the graph. The methods are:\n",
    "- **HNSW Overlap**: This method uses a combination of vector search and graph traversal to find the most relevant information to the query. It uses the HNSW algorithm to search the embeddings of documents, document chunks, entities, and relationships. These results serve as the starting point for the graph traversal. The graph traversal is used to find the most relevant information to the query.\n",
    "\n",
    "- **Vector Search**: This method uses the HNSW algorithm to search the embeddings of one of the document, document chunk, entity, or relationship vector indices. It returns the most relevant information to the query based on the embeddings. This method is what you would expect from a traditional vector RAG solution.\n",
    "\n",
    "- **Sibling Search**: This method is very similar to the Vector Search method, but it uses the sibling (IS_AFTER) relationships between document chunks to expand the context around the document chunk that is most relevant to the query. This method is useful when you want to get more context around the most relevant document chunk.\n",
    "\n",
    "- **GraphRAG (Community Search)**: This method enhances retrieval by leveraging graph structure and community detection. It starts from top-k similar document chunks and performs a graph traversal across relevant relationships to identify communities of related chunks. The traversal is guided by connection patterns in the graph rather than just semantic similarity, enabling richer and more coherent context retrieval. GraphRAG is especially effective in complex knowledge graphs where multi-hop reasoning or structural connections are important.\n",
    "\n",
    "TigerGraph CoPilot provides a way to generate the response to the user's query using a LLM, based on the search results from the methods above. You can compare the responses generated by the LLM for each of the search methods to see which one is the most relevant to the user's query. In this example, we can see that the HNSW Overlap method generates the most relevant response to the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how to load data to tigergraph vector store, give an example in Python\"\n",
    "print(f\"\"\"Fetching answer for question: {query}\"\"\")\n",
    "\n",
    "resp = conn.ai.answerQuestion(\n",
    "    query,\n",
    "    method=\"hnswoverlap\",\n",
    "    method_parameters = {\n",
    "        \"indices\": [\"Document\", \"DocumentChunk\", \"Entity\", \"Relationship\"],\n",
    "        \"top_k\": 2,\n",
    "        \"num_hops\": 2,\n",
    "        \"num_seen_min\": 2,\n",
    "        \"verbose\": True\n",
    "    })\n",
    "\n",
    "print(f\"\"\"\\nAnswer using HNSW_Overlap:\\n{resp[\"response\"]}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"vdb\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"withHyDE\": False})\n",
    "\n",
    "print(f\"\"\"\\nAnswer using HNSW:\\n{resp[\"response\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(\n",
    "    query,\n",
    "    method=\"graphrag\",\n",
    "    method_parameters={\n",
    "        \"community_level\": 2,\n",
    "        \"combine\": False,\n",
    "        \"top_k\": 5,\n",
    "        \"verbose\": True\n",
    "    })\n",
    "\n",
    "print(f\"\"\"\\nAnswer using GraphRAG:\\n{resp[\"response\"]}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
